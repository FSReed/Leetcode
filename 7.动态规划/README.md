# 动态规划心得

- 记忆化搜索翻译成递推需要自己多动手写，写多了就会有自己的体会。翻译过程中最难的往往是**确定边界条件**，也就是如何初始化数组，我目前很难一眼瞪出来，还是要先简单写一下递归的边界，根据这个边界去初始化dp数组
- 翻译成递推的过程中要注意状态转移的过程，如果从更大的下标转移到更小的下标，这个状态递推时应该**倒序枚举**，状态机dp/区间dp很多题目都涉及这个问题
- 体会到了**数据范围**的重要性，有时候通过数据范围就可以判断状态选择是否合理([参考题目](<./7.3-区间DP/1547. 切棍子的最小成本.md>))
- 递推**并非永远**优于记忆化搜索，有时候记忆化搜索可以通过剪枝避免一些状态的计算（比如已经找到了答案，提前结束），而递推是需要计算所有状态的([参考题目](<./7.3-区间DP/3040. 相同分数的最大操作数目 II.md>))
- 多维dp有时会有一个维度依赖于其他的维度，这时可以考虑降维([参考题目](<./7.3-区间DP/1000. 合并石头的最低成本.md>))

## 代码性能相关

- **别再用`std::function`了**！([参考题目](<./7.4-树形DP/树的直径/3203. 合并两棵树后的最小直径.md>))。这是AI的说法：
  1. 类型擦除 (Type Erasure) 与 虚函数开销 std::function 是一个通用的多态函数包装器。为了能够存储任意类型的可调用对象（函数指针、lambda、仿函数等），它内部使用了“类型擦除”技术。这意味着每次调用 dfs(...) 时，程序不能直接跳转到函数地址，而是必须通过类似“虚函数表”的机制进行间接调用 (Indirect Call)。这比直接调用慢得多。
  2. 无法内联 (No Inlining) C++ 编译器极其擅长优化代码，尤其是“内联”——将函数体直接展开到调用处，省去函数调用的开销，编译器清楚地知道 dfs 具体是哪个 lambda 对象，因此可以极其激进地进行内联优化。由于 std::function 擦除了类型，编译器在编译期不知道里面具体存的是什么，因此无法内联。
  3. 堆内存分配 (Heap Allocation) 虽然 std::function 有小对象优化 (Small Object Optimization)，但如果捕获的上下文（closure）稍大，或者实现机制不同，它可能会在堆上动态分配内存来存储 lambda 对象。而原生的 lambda 对象通常只在栈上分配，速度极快。
